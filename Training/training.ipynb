{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout,LeakyReLU,Flatten,AveragePooling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f882d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare variables and images folders\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "input_shape = (image_size, image_size, 3)\n",
    "train_folders = '../data/train/'\n",
    "validation_folders = '../data/validation/'\n",
    "test_folders = '../data/test/'\n",
    "\n",
    "quantity_tr = {} \n",
    "quantity_te = {}\n",
    "\n",
    "for folder in os.listdir(train_folders):\n",
    "    quantity_tr[folder] = len(os.listdir(train_folders+folder))\n",
    "\n",
    "for folder in os.listdir(validation_folders):\n",
    "    quantity_te[folder] = len(os.listdir(validation_folders+folder))\n",
    "    \n",
    "quantity_train = pd.DataFrame(list(quantity_tr.items()), index=range(0,len(quantity_tr)), columns=['class','count'])\n",
    "quantity_test = pd.DataFrame(list(quantity_te.items()), index=range(0,len(quantity_te)), columns=['class','count'])\n",
    "\n",
    "figure, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.barplot(x='class',y='count',data=quantity_train,ax=ax[0])\n",
    "sns.barplot(x='class',y='count',data=quantity_test,ax=ax[1])\n",
    "\n",
    "print(\"Number of images in the train set : \", sum(quantity_tr.values()))\n",
    "print(\"Number of images in the validation set ; \",sum(quantity_te.values()))\n",
    "number_of_images_in_test_set = len(os.listdir(test_folders))\n",
    "print(\"Number of images in test set : \",number_of_images_in_test_set)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets with dataaugmentation initialized for training set\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   rotation_range=25,\n",
    "                                   fill_mode='nearest',\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   brightness_range=(0.5, 1.5),\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(train_folders,\n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "validation_dataset = validation_datagen.flow_from_directory(validation_folders,\n",
    "                                                            target_size=(image_size, image_size),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            shuffle=False,\n",
    "                                                            class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "test_dataset = test_datagen.flow_from_directory(test_folders,\n",
    "                                                target_size=(image_size, image_size),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the classes in the dataset\n",
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb11fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map_classes = {v: k for k, v in validation_dataset.class_indices.items()}\n",
    "print(validation_dataset.class_indices)\n",
    "print(inv_map_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to show images or classify them if predict_using_model is true\n",
    "\n",
    "def show_few_images(number_of_examples=2, predict_using_model=None):\n",
    "    figure1, ax1 = plt.subplots(number_of_examples,len(os.listdir(train_folders)), figsize=(20,4*number_of_examples))\n",
    "    ax1 = ax1.reshape(-1)\n",
    "    axoff_fun = np.vectorize(lambda ax:ax.axis('off'))\n",
    "    axoff_fun(ax1)\n",
    "    axs = 0\n",
    "    for i, folder in enumerate(os.listdir(train_folders)):\n",
    "        image_ids = os.listdir(os.path.join(train_folders,folder))\n",
    "        for j in [random.randrange(0, len(image_ids)) for i in range(0,number_of_examples)]:\n",
    "            img_path = os.path.join(train_folders,folder,image_ids[j])\n",
    "            display = plt.imread(img_path)\n",
    "            img = cv2.resize(cv2.imread(img_path), (image_size, image_size))\n",
    "            img_normalized = img/255\n",
    "            plt.axis('off')\n",
    "            ax1[axs].imshow(display)\n",
    "            title = 'True:'+folder\n",
    "            if(predict_using_model):\n",
    "                predicted_classname = inv_map_classes[np.argmax(best_model.predict(np.array([img_normalized])))]\n",
    "                title = title+'\\nPredict :'+predicted_classname\n",
    "            ax1[axs].set_title(title)\n",
    "            axs=axs+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9290d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_few_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save history to file to be able to load it later\n",
    "def save_history(history, model_name):\n",
    "    #convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "    # save to json:  \n",
    "    hist_json_file = model_name+'_history.json' \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "    # or save to csv: \n",
    "    hist_csv_file = model_name+'_history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "#plot accuracy from model created, can be modified to plot from file history       \n",
    "def plot_accuracy_from_history(history):\n",
    "    color = sns.color_palette()\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
    "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "#plot the loss\n",
    "def plot_loss_from_history(history):\n",
    "    color = sns.color_palette()\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    sns.lineplot(epochs, loss,label='Training Loss')\n",
    "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "#things to do after training    \n",
    "def do_history_stuff(history, history_file_name):\n",
    "    save_history(history, history_file_name)\n",
    "    plot_accuracy_from_history(history)\n",
    "    plot_loss_from_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28decd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get class weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_dataset.classes),\n",
    "                                        y = train_dataset.classes                                                    \n",
    "                                    )\n",
    "train_class_weights = dict(zip(np.unique(train_dataset.classes), class_weights))\n",
    "print(train_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "inception_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58443f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model and view it summary\n",
    "InceptionV3_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "\n",
    "InceptionV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze upper layers of model\n",
    "for layer in InceptionV3_model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in InceptionV3_model.layers[249:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f985d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ad add layers to the model\n",
    "InceptionV3_last_output = InceptionV3_model.output\n",
    "InceptionV3_maxpooled_output = Flatten()(InceptionV3_last_output)\n",
    "InceptionV3_x = Dense(1024, activation='relu')(InceptionV3_maxpooled_output)\n",
    "InceptionV3_x = Dropout(0.5)(InceptionV3_x)\n",
    "InceptionV3_x = Dense(3, activation='softmax')(InceptionV3_x)\n",
    "\n",
    "InceptionV3_x_final_model = Model(inputs=InceptionV3_model.input,outputs=InceptionV3_x)\n",
    "\n",
    "InceptionV3_x_final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6573059",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "number_of_epochs = inception_epoch\n",
    "#compile model with optimizer\n",
    "\n",
    "# Adam(learning_rate=base_learning_rate, decay=base_learning_rate/40)\n",
    "InceptionV3_x_final_model.compile(optimizer=SGD(learning_rate=base_learning_rate, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "InceptionV3_filepath = 'inceptionv3_'+'-saved-model-{epoch:02d}-loss-{loss:.2f}.h5'\n",
    "\n",
    "#save model as checkpoint\n",
    "checkpoint = ModelCheckpoint(InceptionV3_filepath, monitor='val_accuracy', mode='max',verbose=1, save_best_only=True)\n",
    "# restore_best_weights=True verbose=1,mode='max'\n",
    "\n",
    "#stop model if loss does not reduce in 25 epochs\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=25)\n",
    "learning_rate_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "callback_list = [checkpoint, early_stopping, learning_rate_reduce]\n",
    "\n",
    "InceptionV3_history = InceptionV3_x_final_model.fit(train_dataset, epochs = number_of_epochs,\n",
    "                                                    validation_data = validation_dataset,\n",
    "                                                    class_weight = train_class_weights,\n",
    "                                                    callbacks=callback_list, verbose=1)\n",
    "\n",
    "best_model = InceptionV3_x_final_model\n",
    "model_history = InceptionV3_history\n",
    "\n",
    "do_history_stuff(InceptionV3_history, 'InceptionV3_model') #plot accuracy and loss after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate accuracy of model\n",
    "test_score = best_model.evaluate(test_dataset)\n",
    "\n",
    "print(\"\")\n",
    "print(\"[INFO] Accuracy: {:.2f}%\".format(test_score[1] * 100))\n",
    "print(\"[INFO] Loss: \",test_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy and loss from training history\n",
    "plot_accuracy_from_history(model_history)\n",
    "plot_accuracy_from_history(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the confusion matrix.\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7,7))\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "target_names = []\n",
    "for key in train_dataset.class_indices:\n",
    "    target_names.append(key)\n",
    "    \n",
    "#Confusion Matrix\n",
    "\n",
    "Y_pred = best_model.predict(test_dataset)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(test_dataset.classes, y_pred)\n",
    "plot_confusion_matrix(cm, target_names)\n",
    "\n",
    "#Print Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(test_dataset.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a few images and their prediction from validation set\n",
    "show_few_images(3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "model = load_model(\"inceptionv3_-saved-model-76-loss-0.37.h5\")\n",
    "img_path = 'test.jpg'\n",
    "test_image = image.load_img(img_path, target_size =(image_size,image_size))\n",
    "plt.imshow(test_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "test_image = image.img_to_array(test_image)\n",
    "# Expanding the 3-d image to 4-d image.\n",
    "# The dimensions will be Batch, Height, Width, Channel\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "# Predicting the final class\n",
    "predict = model.predict(test_image)\n",
    "predictions = predict[0].argmax()\n",
    "confidence = round(100 * (np.max(predict[0])), 2)\n",
    "if predictions == 0:\n",
    "    print(\"The test image has: Age Related Macular Degeneration with confidence of:\", confidence, \"%\")\n",
    "elif predictions == 1:\n",
    "    print(\"The test image has: Diabetic Retinopathy confidence of:\", confidence, \"%\")\n",
    "else:\n",
    "    print(\"The test image is: healthy: with confidence of:\",confidence ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version=max([int(i) for i in os.listdir(\"../models/retrain\") + [0]])+1\n",
    "best_model.save(f\"../models/retrain/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3ddc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
